{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [],
   "source": [
    "# Import functions\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from brats.load_data import load_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of samples: 167\n",
      "The number of columns: 725\n",
      "The number of samples: 167\n",
      "The number of columns: 709\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "data = load_data()\n",
    "print(f'The number of samples: {len(data.index)}')\n",
    "print(f'The number of columns: {len(data.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "remove_features = data.T[data.isna().sum(axis=0) < 0.8 * len(data.index)] # Remove features with more than 80% Nans\n",
    "removed_features = remove_features.T\n",
    "print(f'The number of samples: {len(removed_features)}')\n",
    "print(f'The number of columns: {len(removed_features.columns)}')\n",
    "\n",
    "label = removed_features['label'].to_numpy() #extract labels\n",
    "data_nolabels = removed_features.drop('label', axis=1) #dropped last column (labels)\n",
    "data_nodiv = data_nolabels.replace(r'#DIV/0!', 'nan', regex=True) #DIV's are replace by nan \n",
    "features = data_nodiv.replace(np.inf, np.nan, regex=True) #inf is replaced by nan\n",
    "labels = label=='GBM' #convert labels to true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute remaining Nans\n",
    "imputer = KNNImputer(n_neighbors=10)            #definieert functie K-nearest neighbor imputer\n",
    "X_train = imputer.fit_transform(X_train)        #train k-NN imputer on train data\n",
    "X_test = imputer.transform(X_test)              # apply k-NN imputer to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "# Assessment Data \n",
    "from scipy import stats\n",
    "\n",
    "# Normal Distribution of Features \n",
    "\n",
    "k2, p = stats.normaltest(X_train)\n",
    "alpha = 0.05\n",
    "count_normal = 0 \n",
    "for value in p:\n",
    "    if value > alpha:  \n",
    "        count_normal += 1\n",
    "print(count_normal)\n",
    "\n",
    "# Correlation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "data_train = scaler.transform(X_train)\n",
    "label_df = pd.DataFrame(data=y_train, columns=['target'])\n",
    "\n",
    "#PCA\n",
    "pca = PCA().fit(data_train)\n",
    "pca_data = pca.transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_linear = Pipeline([('scalar1',StandardScaler()),\n",
    "#                      ('pca1',PCA(n_components=10)),\n",
    "#                      ('lr_classifier',LinearDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_quadratic = Pipeline([('scalar2',StandardScaler()),\n",
    "#                      ('pca4',PCA(n_components=10)),\n",
    "#                      ('qda_classifier',QuadraticDiscriminantAnalysis())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines = [pipeline_linear, pipeline_quadratic]\n",
    "# best_accuracy=0.0\n",
    "# best_classifier=0\n",
    "# best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary of pipelines and classifier types for ease of reference\n",
    "# pipe_dict1 = {0: 'Linear Discriminant Analysis', 1: 'Quadratic Discriminant Analysis'}\n",
    "\n",
    "# rskf = StratifiedKFold(n_splits=5) \n",
    "\n",
    "# for train_index, validate_index in rskf.split(X_train, y_train):\n",
    "# \tdata_train, data_validate = X_train[train_index], X_train[validate_index]\n",
    "# \tlabel_train, label_validate = y_train[train_index], y_train[validate_index]\n",
    "# \tfor pipe in pipelines:\n",
    "# \t\tpipe.fit_transf(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    axes.set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes.set_ylim(*ylim)\n",
    "    axes.set_xlabel(\"Training examples\")\n",
    "    axes.set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, validate_scores  = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validate_scores_mean = np.mean(validate_scores, axis=1)\n",
    "    validate_scores_std = np.std(validate_scores, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes.grid()\n",
    "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes.fill_between(train_sizes, validate_scores_mean - validate_scores_std,\n",
    "                         validate_scores_mean + validate_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes.plot(train_sizes, validate_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes.legend(loc=\"best\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plot_learning_curve' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd3ac28f986c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_learning_curve' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotten learning curves voor gekozen classifiers \n",
    "clsfs= [LinearDiscriminantAnalysis(), GaussianNB(), SVC(kernel = 'linear', C= 0.001), RandomForestClassifier(max_depth= 20, min_samples_leaf=5, max_leaf_nodes=10)]\n",
    "data_train = PCA(n_components=0.95).fit_transform(data_train)\n",
    "\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "num = 0\n",
    "\n",
    "for clf in clsfs:\n",
    "    title = str(type(clf))\n",
    "    ax = fig.add_subplot(2, 2, num + 1)\n",
    "    plot_learning_curve(clf, title, data_train, y_train, ax, ylim=(0.3, 1.01), cv=rskf)\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=10)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm = Pipeline([('scalar4',StandardScaler()),\n",
    "                     ('pca4',PCA(n_components=10)),\n",
    "                     ('svm_classifier',SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_rf, pipeline_svm]\n",
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict2 = {0: 'Random Forest', 1: 'SVM'}\n",
    "rskf = StratifiedKFold(n_splits=5) \n",
    "\n",
    "for train_index, validate_index in rskf.split(X_train, y_train):\n",
    "\tdata_train, data_validate = X_train[train_index], X_train[validate_index]\n",
    "\tlabel_train, label_validate = y_train[train_index], y_train[validate_index]\n",
    "\tfor pipe in pipelines:\n",
    "\t\tpipe.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest Test Accuracy: 0.8461538461538461\nSVM Test Accuracy: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "#Determine accuracy for each classifier\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict2[i],model.score(data_validate,label_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier with best accuracy:Random Forest\n"
     ]
    }
   ],
   "source": [
    "#Determine best classifier\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(data_validate,label_validate)>best_accuracy:\n",
    "        best_accuracy=model.score(data_validate,label_validate)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy:{}'.format(pipe_dict2[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = StratifiedKFold(n_splits=5) \n",
    "auc= []\n",
    "accuracy= []\n",
    "F1= []\n",
    "precision = []\n",
    "recall= []\n",
    "for train_index, validate_index in rskf.split(X_train, y_train):\n",
    "    data_train, data_validate = X_train[train_index], X_train[validate_index]\n",
    "    label_train, label_validate = y_train[train_index], y_train[validate_index]\n",
    "    # Create a pipeline\n",
    "    pipe = Pipeline([('scalar',StandardScaler()), ('pca',PCA(n_components=0.95)), ('classifier',RandomForestClassifier())])\n",
    "    # Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "    grid_param = [{\"classifier\": [RandomForestClassifier()],\n",
    "                   \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                   \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                   \"classifier__min_samples_leaf\":[2,5,10,15,100],\n",
    "                   \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "    # create a gridsearch of the pipeline, the fit the best model\n",
    "    skf = StratifiedKFold(n_splits=7)\n",
    "    gridsearch = GridSearchCV(pipe, grid_param, cv=skf, verbose=0,n_jobs=-1) # Fit grid search\n",
    "    best_model = gridsearch.fit(data_train,label_train)\n",
    "\n",
    "    # # get roc/auc info\n",
    "    # y_score = best_model.predict_proba(data_validate)[:,1]\n",
    "    # # # fpr = dict()\n",
    "    # # # tpr = dict()\n",
    "    # # # fpr, tpr, _ = roc_curve(label_validate, y_score)\n",
    "    # # # roc_auc = dict()\n",
    "    # # # roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # y_pred=best_model.predict(data_validate)\n",
    "    # auc.append(metrics.roc_auc_score(label_validate, y_score))\n",
    "    # accuracy.append(metrics.accuracy_score(label_validate, y_pred))\n",
    "    # F1.append(metrics.f1_score(label_validate,y_pred))\n",
    "    # precision.append(metrics.precision_score(label_validate,y_pred))\n",
    "    # recall.append(metrics.recall_score(label_validate, y_pred))\n",
    "\n",
    "    y_score = best_model.predict_proba(X_test)[:,1]\n",
    "    y_pred=best_model.predict(X_test)\n",
    "    auc.append(metrics.roc_auc_score(y_test, y_score))\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    F1.append(metrics.f1_score(y_test,y_pred))\n",
    "    precision.append(metrics.precision_score(y_test,y_pred))\n",
    "    recall.append(metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "#Plotting confusion matrix \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_CM(cm,'CM')\n",
    "\n",
    "    # ROCAUC plot \n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # plt.xlim([-0.05, 1.0])\n",
    "    # plt.ylim([0.0, 1.05])\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.grid(True)\n",
    "    # plt.plot(fpr, tpr, label='AUC = {0}'.format(roc_auc))        \n",
    "    # plt.legend(loc=\"lower right\", shadow=True, fancybox =True) \n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.8461538461538463, 0.868131868131868, 0.9047619047619048, 0.8534798534798534, 0.8791208791208791]\n[0.7058823529411765, 0.8235294117647058, 0.8235294117647058, 0.7941176470588235, 0.7941176470588235]\n[0.7916666666666667, 0.8695652173913043, 0.8695652173913043, 0.8372093023255814, 0.8510638297872339]\n[0.7037037037037037, 0.8, 0.8, 0.8181818181818182, 0.7692307692307693]\n[0.9047619047619048, 0.9523809523809523, 0.9523809523809523, 0.8571428571428571, 0.9523809523809523]\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "print(auc)\n",
    "print(accuracy)\n",
    "print(F1)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd0569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}